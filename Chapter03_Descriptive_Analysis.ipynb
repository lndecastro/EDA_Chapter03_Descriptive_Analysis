{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addd9864",
   "metadata": {},
   "source": [
    "# Chapter 03: Descriptive Analysis\n",
    "## Prof. Leandro Nunes de Castro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21acdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This content was created as a supporting material for the textbook\n",
    "# EXPLORATORY DATA ANALYSIS: ...\n",
    "# ... Descriptive Analysis, Visualization and Dashboard Design (with codes in Python)\n",
    "# authored by Leandro de Castro (c), 2023-2024\n",
    "# All rights reserved\n",
    "\n",
    "# Chapter 3 - Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733de915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY\n",
    "# 0. Importing the Libraries and Loading the Chapter Data\n",
    "# 1. Central Tendency and Dispersion Measures: One Variable at a Time\n",
    "# 2. Central Tendency and Dispersion Measures: All Variables at Once\n",
    "# 3. Association Measures\n",
    "# 4. Analyzing Through Visualization\n",
    "# Final challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f5565",
   "metadata": {},
   "source": [
    "##  0. Importing the Libraries and Loading the Chapter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st # Built in Python library for descriptive statistics\n",
    "import pandas as pd  # Data manipulation and analysis library\n",
    "import researchpy as rp  # Open source library focused on univariate and bivariate analysis\n",
    "import numpy as np  # General purpose array processing package\n",
    "import seaborn as sns  # Data visualization library based on matplotlib\n",
    "import matplotlib.pyplot as plt  # Data visualization library\n",
    "import scipy.stats as spy  # Statistical library from Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st # Built in Python library for descriptive statistics\n",
    "import pandas as pd  # Data manipulation and analysis library\n",
    "import researchpy as rp  # Open source library focused on univariate and bivariate analysis\n",
    "import numpy as np  # General purpose array processing package\n",
    "import seaborn as sns  # Data visualization library based on matplotlib\n",
    "import matplotlib.pyplot as plt  # Data visualization library\n",
    "import scipy.stats as spy  # Statistical library from Scipy\n",
    "from scipy.stats import norm, kurtosis, laplace, semicircular\n",
    "from scipy import stats\n",
    "from scipy.stats import gmean, hmean, trim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset1\n",
    "# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass\n",
    "# Missing Values? Yes\n",
    "dmammo = pd.read_csv('mammographic_masses_nominal.csv')\n",
    "dmammo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmammo.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset2\n",
    "# https://archive.ics.uci.edu/ml/datasets/forest+fires\n",
    "# Missing Values? No\n",
    "dforest = pd.read_csv('forestfires.csv')\n",
    "dforest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dforest.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8c812",
   "metadata": {},
   "source": [
    "## Section 3.3: Frequency Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the frequency distribution, frequency table and pie chart \n",
    "# of variable 'Shape' in the Mammographic dataset\n",
    "\n",
    "SShape = pd.Series(dmammo['Shape'])\n",
    "ftable = SShape.value_counts()  # Generate the frequency table\n",
    "rftable = ftable/len(SShape)*100  # Relative frequency\n",
    "cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency\n",
    "df = pd.DataFrame({'Frequency':ftable.to_list(),\n",
    "                   'Relative Frequency':rftable.to_list(),\n",
    "                  'Cumulative Frequency':cftable.to_list()})\n",
    "print(df)\n",
    "fig, figftable = plt.subplots()\n",
    "figftable.pie(ftable.to_list(), labels=ftable.index.to_list(),\n",
    "              autopct='%1.2f%%')  # From Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dforest.head\n",
    "#dforest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d807c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the frequency distribution, frequency table and histogram \n",
    "# of continuous variables in the Forest Fire dataset\n",
    "\n",
    "var = 'temp'  # Choose the target variable\n",
    "SShape = pd.Series(dforest[var])\n",
    "nbins = 10\n",
    "inflimit = 0; suplimit = max(SShape)\n",
    "ampl = (suplimit - inflimit)/nbins\n",
    "\n",
    "# Define the range of the variable and bin size\n",
    "fbins = np.arange(0,suplimit+ampl,ampl)\n",
    "\n",
    "# The pandas.cut function groups the data into bins and counts \n",
    "# the frequency\n",
    "ftable = pd.cut(SShape,fbins).value_counts() # Absolute frequency\n",
    "rftable = ftable/len(SShape)*100  # Relative frequency\n",
    "cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency\n",
    "df = pd.DataFrame({'Bins':ftable.index.to_list(),\n",
    "                   'Frequency':ftable.to_list(),\n",
    "                   'Relative Frequency':rftable.to_list(),\n",
    "                   'Cumulative Frequency':cftable.to_list()})\n",
    "print(df)\n",
    "plt.xticks(fbins)\n",
    "sns.histplot(dforest,x=var,bins=fbins, kde = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE\n",
    "# Using Seaborn to determine the number of bins, bin width and the bin edges\n",
    "# when auto is used for parameter bins in the histplot function\n",
    "dforest = pd.read_csv('forestfires.csv')\n",
    "var = 'temp'\n",
    "ax = sns.histplot(dforest,x=var,bins='auto', kde = 2)\n",
    "num_bins = len(ax.patches)\n",
    "bin_width = (max(dforest[var])-min(dforest[var]))/num_bins\n",
    "num_bins = len(ax.patches)\n",
    "bin_edges = ax.get_xticks()\n",
    "print(num_bins,bin_width,bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions with different shapes \n",
    "# Load the forest fires dataset from UCI\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "sns.histplot(dforest,x='month',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='day',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='FFMC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='DMC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='DC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='ISI',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='RH',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='wind',bins='auto', kde = 2); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions with different shapes \n",
    "# Load the forest fires dataset from UCI\n",
    "# Alternative implementation\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "var = ['month','day','FFMC','DMC','DC','ISI','RH','wind']\n",
    "for i in var:\n",
    "    sns.histplot(dforest,x=i,bins='auto', kde = 2); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Contingency Tables for the Mammographic Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
    "cols = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density', 'Severity']\n",
    "dmammo = pd.read_csv(url, names=cols, na_values='?')\n",
    "\n",
    "# Remove rows with missing values\n",
    "dmammo.dropna(inplace=True)\n",
    "\n",
    "# Print the contingency tables\n",
    "var = ['Shape','Margin','Density']\n",
    "print('**Contingency Tables**')\n",
    "for i in var:\n",
    "    CT = pd.crosstab(dmammo[i], dmammo['Severity'])\n",
    "    print('Variables',i, 'and Severity:\\n',CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9a010",
   "metadata": {},
   "source": [
    "## Section 3.4: Central Tendency and Dispersion Measures \n",
    "### One Variable at a Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93874220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean and mode one by one using the Statistics library\n",
    "# Numeric variables\n",
    "print('**Forest Fires Dataset**')\n",
    "print('\\n*Numeric Variable FFMC*')\n",
    "print('Mean of variable FFMC: {:.2f}'.format(st.mean(dforest['FFMC'])))\n",
    "print('Median of variable FFMC: {:.2f}'.format(st.median(dforest['FFMC'])))\n",
    "midpoint = (max(dforest['FFMC'])+min(dforest['FFMC']))/2\n",
    "print('Midpoint of variable FFMC: {:.2f}'.format(midpoint))\n",
    "\n",
    "print('\\n*Numeric Variable temp*')\n",
    "print('Mean of variable temp: {:.2f}'.format(st.mean(dforest['temp'])))\n",
    "print('Median of variable temp: {:.2f}'.format(st.median(dforest['temp'])))\n",
    "midpoint = (max(dforest['temp'])+min(dforest['temp']))/2\n",
    "print('Midpoint of variable temp: {:.2f}'.format(midpoint))\n",
    "\n",
    "# Nominal variables\n",
    "print('\\n*Categorical Variables*')\n",
    "print('Mode of nominal variable month: {v1}'\n",
    "      .format(v1=st.mode(dforest['month'])))\n",
    "print('Mode of nominal variable day: {v1}'\n",
    "      .format(v1=st.mode(dforest['day'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ce7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the central tendency measures over the histogram \n",
    "var = 'temp'  # Choose the target variable\n",
    "mean = st.mean(dforest[var])\n",
    "median = st.median(dforest[var])\n",
    "midpoint = (max(dforest[var])+min(dforest[var]))/2\n",
    "print('Mean, median and midpoint for temp:',mean,median,midpoint)\n",
    "sns.histplot(dforest,x=var,bins='auto', kde = 2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')\n",
    "plt.legend() # Add a legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE\n",
    "# Calculating the mean and mode one by one using the Statistics library\n",
    "# Numeric variables\n",
    "print('**Forest Fires Dataset**')\n",
    "print('\\n*Numeric Variables*')\n",
    "print('Mean of variable X: {:.2f}'.format(st.mean(dforest['X'])))\n",
    "print('Mean of variable Y: {:.2f}'.format(st.mean(dforest['Y'])))\n",
    "print('Mean of variable FFMC: {:.2f}'.format(st.mean(dforest['FFMC'])))\n",
    "print('Mean of variable DMC: {:.2f}'.format(st.mean(dforest['DMC'])))\n",
    "print('Mean of variable DC: {:.2f}'.format(st.mean(dforest['DC'])))\n",
    "print('Mean of variable ISI: {:.2f}'.format(st.mean(dforest['ISI'])))\n",
    "print('Mean of variable temp: {:.2f}'.format(st.mean(dforest['temp'])))\n",
    "print('Mean of variable RH: {:.2f}'.format(st.mean(dforest['RH'])))\n",
    "print('Mean of variable wind: {:.2f}'.format(st.mean(dforest['wind'])))\n",
    "print('Mean of variable rain: {:.2f}'.format(st.mean(dforest['rain'])))\n",
    "print('Mean of variable area: {:.2f}'.format(st.mean(dforest['area'])))\n",
    "\n",
    "# Nominal variables\n",
    "print('\\n*Categorical Variables*')\n",
    "print('Mode of nominal variable month: {v1}'\n",
    "      .format(v1=st.mode(dforest['month'])))\n",
    "print('Mode of nominal variable day: {v1}'\n",
    "      .format(v1=st.mode(dforest['day'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean of a frequency distribution (Eq. 3.4)\n",
    "# Create a DataFrame from the frequency distribution data\n",
    "data = {'Bins': ['(16.65, 19.98]', '(19.98, 23.31]', '(13.32, 16.65]',\n",
    "                 '(23.31, 26.64]', '(9.99, 13.32]', '(26.64, 29.97]',\n",
    "                 '(3.33, 6.66]', '(6.66, 9.99]', '(29.97, 33.3]',\n",
    "                 '(0.0, 3.33]'],\n",
    "        'Frequency': [128, 119, 75, 69, 47, 30, 20, 15, 13, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "# Calculate the midpoint of each bin (interval)\n",
    "df['Midpoint'] = (df['Bins'].str.split(', ').str[0].str.replace('(', '')\n",
    "                  .astype(float) +\n",
    "                  df['Bins'].str.split(', ').str[1].str.replace(']', '')\n",
    "                  .astype(float))/2\n",
    "# Multiply the midpoint by the frequency to get the product\n",
    "df['Product_fx'] = df['Midpoint'] * df['Frequency']\n",
    "# Sum the products and frequencies\n",
    "sprod = df['Product_fx'].sum()\n",
    "sfreq = df['Frequency'].sum()\n",
    "# Calculate the mean\n",
    "mean = sprod / sfreq\n",
    "print(df)\n",
    "print('Mean of the frequency distribution: {:.2f}'.format(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab35fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted average (Eq. 3.5), geometric (Eq. 3.6) \n",
    "# harmonic (Eq. 3.7), and trimmed (Eq. 3.8) means\n",
    "\n",
    "var = 'FFMC'\n",
    "weights = np.random.randn(len(dforest[var]))\n",
    "wavg = np.average(dforest[var], weights=weights)\n",
    "gavg = spy.gmean(dforest[var])  # From Scipy library\n",
    "havg = spy.hmean(dforest[var])  # From Scipy library\n",
    "tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim\n",
    "\n",
    "print('Weighted average of variable FFMC: {:.2f}'.format(wavg))\n",
    "print('Geometric mean of variable FFMC: {:.2f}'.format(gavg))\n",
    "print('Harmonic mean of variable FFMC: {:.2f}'.format(havg))\n",
    "print('Trimmed mean of variable FFMC: {:.2f}'.format(tavg))\n",
    "\n",
    "var = 'temp'\n",
    "weights = np.random.randn(len(dforest[var]))\n",
    "wavg = np.average(dforest[var], weights=weights)\n",
    "gavg = spy.gmean(dforest[var])  # From Scipy library\n",
    "havg = spy.hmean(dforest[var])  # From Scipy library\n",
    "tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim\n",
    "\n",
    "print('\\nWeighted average of variable temp: {:.2f}'.format(wavg))\n",
    "print('Geometric mean of variable temp: {:.2f}'.format(gavg))\n",
    "print('Harmonic mean of variable temp: {:.2f}'.format(havg))\n",
    "print('Trimmed mean of variable temp: {:.2f}'.format(tavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendency Measures for the Forest Fires Dataset\n",
    "# Columns of interest: 'FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'\n",
    "\n",
    "ffmc = dforest['FFMC']; dmc = dforest['DMC']; dc = dforest['DC']\n",
    "isi = dforest['ISI']; temp = dforest['temp']; rh = dforest['RH']\n",
    "wind = dforest['wind']; rain = dforest['rain']\n",
    "\n",
    "# Dictionary to store the results\n",
    "CTM = {}\n",
    "\n",
    "# Loop over the columns and calculate the statistics\n",
    "for col_name, col_data in zip(['FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'],\n",
    "                              [ffmc, dmc, dc, isi, temp, rh, wind, rain]):\n",
    "    mean = np.mean(col_data)\n",
    "    median = np.median(col_data)\n",
    "    midpoint = (np.max(col_data) + np.min(col_data)) / 2\n",
    "    wavg = np.average(col_data, weights=dforest['area'])\n",
    "    gavg = spy.gmean(col_data)\n",
    "    havg = spy.hmean(col_data)\n",
    "    tavg = spy.trim_mean(col_data, proportiontocut=0.1)\n",
    "    # Add the results to the dictionary\n",
    "    CTM[col_name] = {'Mean': mean,\n",
    "                         'Median': median,\n",
    "                         'Midpoint': midpoint,\n",
    "                         'Weighted Mean': wavg,\n",
    "                         'Geometric Mean': gavg,\n",
    "                         'Harmonic Mean': havg,\n",
    "                         'Trimmed Mean': tavg}\n",
    "    \n",
    "# Print the results\n",
    "for col_name, col_results in CTM.items():\n",
    "    print(col_name)\n",
    "    for stat_name, stat_value in col_results.items():\n",
    "        print(f\"\\t{stat_name}: {stat_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4bedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variability measures range (Eq. 3.9), \n",
    "# IQR (Eq. 3.10), sIQR (Eq. 3.11), variance (Eq. 3.12), \n",
    "# std (Eq. 3.14), and CV (Eq. 3.16) using Numpy\n",
    "\n",
    "var = 'FFMC'\n",
    "drange = np.max(dforest[var]) - np.min(dforest[var])\n",
    "Q1, Q3 = np.percentile(dforest[var], [25,75])\n",
    "IQR = Q3 - Q1\n",
    "sIQR = IQR / 2\n",
    "dvar = np.var(dforest[var])\n",
    "dstd = np.std(dforest[var])\n",
    "CV = dstd / np.mean(dforest[var]) * 100\n",
    "\n",
    "print('*Variability Measures*')\n",
    "print('Range of variable FFMC: {:.2f}'.format(drange))\n",
    "print('IQR of variable FFMC: {:.2f}'.format(IQR))\n",
    "print('sIQR of variable FFMC: {:.2f}'.format(sIQR))\n",
    "print('Variance of variable FFMC: {:.2f}'.format(dvar))\n",
    "print('Standard deviation of variable FFMC: {:.2f}'.format(dstd))\n",
    "print('Variation coefficient of variable FFMC: {:.2f}'.format(CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e067188",
   "metadata": {},
   "source": [
    "## Measures of Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Skewed distributions\n",
    "# Generate random data with a right-skewed distribution\n",
    "from scipy.stats import skew\n",
    "\n",
    "data = np.random.beta(a=1, b=5, size=1000) # Beta distribution\n",
    "mean = st.mean(data)\n",
    "median = st.median(data)\n",
    "mode = st.mode(data)\n",
    "print('Mean, median and mode: {:.2f} {:.2f} {:.2f}'\n",
    "      .format(mean,median,mode))\n",
    "print('Skewness (Fischer-Pearson Coefficient): {:.2f}'\n",
    "      .format(skew(data)))\n",
    "print('Skewness (First Skewness Coefficient): {:.2f}'\n",
    "      .format((mean-mode)/np.std(data)))\n",
    "sns.histplot(data,bins='auto', kde = 2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=mode, color='b', linestyle=':', label='Mode')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Skewed distributions\n",
    "# Generate random data with a left-skewed distribution\n",
    "from scipy.stats import skew\n",
    "\n",
    "data_neg = np.random.beta(a=5, b=1, size=1000) # Beta distribution\n",
    "mean = st.mean(data_neg)\n",
    "median = st.median(data_neg)\n",
    "mode = st.mode(data_neg)\n",
    "print('Mean, median and mode: {:.2f} {:.2f} {:.2f}'\n",
    "      .format(mean,median,mode))\n",
    "print('Skewness (Fischer-Pearson Coefficient): {:.2f}'\n",
    "      .format(skew(data_neg)))\n",
    "print('Skewness (First Skewness Coefficient): {:.2f}'\n",
    "      .format((mean-mode)/np.std(data_neg)))\n",
    "sns.histplot(data_neg,bins='auto', kde = 2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=mode, color='b', linestyle=':', label='Mode')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f083eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis: mesokurtic, platykurtic and leptokurtic distributions\n",
    "\n",
    "# Normal distribution (Mesokurtic)\n",
    "dnorm = norm.rvs(size=10000)\n",
    "print(type(dnorm))\n",
    "k = spy.kurtosis(dnorm)\n",
    "print('Kurtosis: {:.2f}'.format(k))\n",
    "sns.histplot(dnorm,bins='auto', kde = 2)\n",
    "plt.title(f\"Normal Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Uniform distribution (Platykurtic)\n",
    "dunif = np.random.uniform(0.01, 0.10, 10000)\n",
    "k = spy.kurtosis(dunif)\n",
    "print('Kurtosis: {:.2f}'.format(k))\n",
    "sns.histplot(dunif,bins='auto', kde = 2)\n",
    "plt.title(f\"Uniform Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Laplace distribution (Leptokurtic)\n",
    "dlap = laplace.rvs(loc=0, scale=1, size=10000)\n",
    "k = spy.kurtosis(dlap)\n",
    "sns.histplot(dlap, bins='auto', kde = 2)\n",
    "plt.title(f\"Laplace Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Wigner semicircle distribution\n",
    "dwigner = semicircular.rvs(size=10000)\n",
    "k = spy.kurtosis(dwigner)\n",
    "sns.histplot(dwigner, bins='auto', kde = 2)\n",
    "plt.title(f\"Wigner Semicircle Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Skewness and Kurtosis for the Forest Fires variables\n",
    "\n",
    "# load dataset\n",
    "dforest = pd.read_csv(\"forestfires.csv\")\n",
    "\n",
    "# Skewness and kurtosis for each variable\n",
    "skewness = dforest[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']].skew()\n",
    "kurt = dforest[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']].kurtosis()\n",
    "\n",
    "# Print the results and classify the kurtosis\n",
    "for var in skewness.index:\n",
    "    print(f\"{var} Skewness: {skewness[var]:.2f}\")\n",
    "    if kurt[var] > 0:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Leptokurtic)\")\n",
    "    elif kurt[var] < 0:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Platykurtic)\")\n",
    "    else:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Mesokurtic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070fa60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Normal Distributions \n",
    "\n",
    "# Define an array of mean and standard deviation values\n",
    "vmu = np.array([-1,0,1])\n",
    "vsigma = np.array([.5,1,1.5])\n",
    "\n",
    "# Create an array of x-values\n",
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "# Loop through the mean and standard deviation values and plot the normal\n",
    "# distributions\n",
    "for mu,sigma in zip(vmu,vsigma):\n",
    "    y = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-((x-mu)**2)/(2*sigma**2))\n",
    "    plt.plot(x, y, label=f'μ={mu},σ={sigma}')\n",
    "\n",
    "# Add a legend and axis labels\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Normal Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc31707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE\n",
    "# Plot Normal Distributions using the pdf() function from Scipy\n",
    "\n",
    "# Define an array of mean and standard deviation values\n",
    "vmu = np.array([-1,0,1])\n",
    "vsigma = np.array([.5,1,1.5])\n",
    "\n",
    "# Create an array of x-values\n",
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "# Loop through the mean and standard deviation values and plot the normal distributions\n",
    "for mu,sigma in zip(vmu,vsigma):\n",
    "    y = norm.pdf(x, mu, sigma)\n",
    "    plt.plot(x, y, label=f'μ={mu},σ={sigma}')\n",
    "\n",
    "# Add a legend and axis labels\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Normal Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Normal Distribution detaching σ = {-3,-2,-1,0,1,2,3} \n",
    "\n",
    "# Define the range of x values (which correspond to z-scores)\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "\n",
    "# Calculate the probability density function (PDF) for the normal \n",
    "# distribution\n",
    "y = (1 / (np.sqrt(2 * np.pi))) * np.exp(-(x ** 2) / 2)\n",
    "\n",
    "# Set up the plot, plot the PDF and vertical lines\n",
    "fig, vax = plt.subplots()\n",
    "vax.plot(x, y)\n",
    "std = 1; mean = 0\n",
    "\n",
    "for i in range(-3, 4):\n",
    "    vax.axvline(mean + i * std, color='r', linestyle='--')\n",
    "\n",
    "# Add a legend and labels to the plot\n",
    "vax.set_xlabel(\"x\")\n",
    "vax.set_ylabel(\"PDF\")\n",
    "vax.set_title(\"Normal Distribution with Standard Deviation Lines\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d756b",
   "metadata": {},
   "source": [
    "## Section 3.5: Measures of Association "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the Covariance Matrix of the Forest Fires dataset\n",
    "\n",
    "# Load the dataset\n",
    "dforest = pd.read_csv('forestfires.csv')\n",
    "\n",
    "# Select the desired numeric features\n",
    "features = ['X','Y','FFMC','DMC','DC','ISI','temp','RH','wind','rain']\n",
    "\n",
    "# Compute the covariance matrix and format to two decimal places\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "Mcov = dforest[features].cov()\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(Mcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Coefficients: PCC, SRCC and KRCC\n",
    "# for the numerical variables of the Forest Fires dataset\n",
    "\n",
    "# Read the data into a pandas dataframe\n",
    "dforest = pd.read_csv(\"forestfires.csv\")\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Calculate PCC, SRCC, KRCC\n",
    "print('**Forest Fires Dataset: PCC, SRCC, KRCC**')\n",
    "PCC = dforest.corr(method='pearson')\n",
    "print('Pearson Correlation Coefficient (PCC)\\n',PCC)\n",
    "SRCC = dforest.corr(method='spearman')\n",
    "print('\\nSpearman Rank Correlation Coefficient (SRCC)\\n',SRCC)\n",
    "KRCC = dforest.corr(method='kendall')\n",
    "print('\\nKramers Rank Correlation Coefficient (KRCC)\\n',KRCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Coefficients: Chi-square, Cramer's V and Point Biserial \n",
    "# for the categorical variables of the Mammographic dataset\n",
    "from scipy import stats\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# Read the data from URL into a pandas dataframe\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
    "cols = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density', 'Severity']\n",
    "dmammo = pd.read_csv(url, names=cols, na_values='?')\n",
    "dmammo.dropna(inplace=True)  # Remove rows with missing values\n",
    "\n",
    "# Chi-square and Cramer's V\n",
    "cvars = ['Shape', 'Margin', 'Density', 'Severity']  # Categorical variables\n",
    "chis = pd.DataFrame()\n",
    "phi = pd.DataFrame()\n",
    "for var1 in cvars:\n",
    "    for var2 in cvars:\n",
    "        if var1 != var2:\n",
    "            chi2, p, dof, ex = stats.chi2_contingency(pd.crosstab(dmammo[var1], dmammo[var2]))\n",
    "            chis.loc[var1, var2] = chi2\n",
    "            phi.loc[var1, var2] = np.sqrt(chi2 / (dmammo.shape[0] * (min(ex.shape) - 1)))\n",
    "print('\\n**Mammographic Dataset: Chi-Square, Krammers V, PBCC**\\n')\n",
    "print('Chi-Square Correlation Coefficient (chi^2)\\n',chis)\n",
    "print('\\nKramers V Correlation Coefficient (phi)\\n',phi)\n",
    "\n",
    "# Point Biserial Correlation between Age and Severity\n",
    "PBCC, pval = pointbiserialr(dmammo['Severity'], dmammo['Age'])\n",
    "print('\\nPBCC between Age and Severity: {:.2f}'.format(PBCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f634c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots between pairs of variables from the Forest Fires dataset\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "\n",
    "# Extract the relevant columns\n",
    "cols = ['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']\n",
    "dforest = dforest[cols]\n",
    "df = dforest\n",
    "\n",
    "# Generate the scatter plots\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "axs[0, 0].scatter(df['DMC'], df['DC'], alpha=0.5)\n",
    "axs[0, 0].set_xlabel('DMC'); axs[0, 0].set_ylabel('DC')\n",
    "axs[0, 0].set_title('PCC: {:.2f}'.format(df['DMC'].corr(df['DC'], method='pearson')))\n",
    "axs[0, 1].scatter(dforest['FFMC'], dforest['ISI'], alpha=0.5)\n",
    "axs[0, 1].set_xlabel('FFMC'); axs[0, 1].set_ylabel('ISI')\n",
    "axs[0, 1].set_title('PCC: {:.2f}'.format(df['FFMC'].corr(df['ISI'], method='pearson')))\n",
    "axs[1, 0].scatter(dforest['temp'], dforest['RH'], alpha=0.5)\n",
    "axs[1, 0].set_xlabel('temp'); axs[1, 0].set_ylabel('RH')\n",
    "axs[1, 0].set_title('PCC: {:.2f}'.format(df['temp'].corr(df['RH'], method='pearson')))\n",
    "axs[1, 1].scatter(dforest['temp'], dforest['wind'], alpha=0.5)\n",
    "axs[1, 1].set_xlabel('temp'); axs[1, 1].set_ylabel('wind')\n",
    "axs[1, 1].set_title('PCC: {:.2f}'.format(df['temp'].corr(df['wind'], method='pearson')))\n",
    "axs[2, 0].scatter(dforest['wind'], dforest['area'], alpha=0.5)\n",
    "axs[2, 0].set_xlabel('wind'); axs[2, 0].set_ylabel('area')\n",
    "axs[2, 0].set_title('PCC: {:.2f}'.format(df['wind'].corr(df['area'], method='pearson')))\n",
    "axs[2, 1].scatter(dforest['rain'], dforest['DC'], alpha=0.5)\n",
    "axs[2, 1].set_xlabel('rain'); axs[2, 1].set_ylabel('DC')\n",
    "axs[2, 1].set_title('PCC: {:.2f}'.format(df['rain'].corr(df['DC'], method='pearson')))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset with categorical variables\n",
    "#df = pd.read_csv('my_data.csv')\n",
    "\n",
    "# Calculate the correlation matrix using Cramer's V\n",
    "corr_matrix = dmammo.corr(method='kendall')\n",
    "\n",
    "# Create the heatmap using seaborn\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Extract the relevant columns\n",
    "cols = ['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']\n",
    "df = df[cols]\n",
    "\n",
    "# Create a scatter plot matrix\n",
    "pd.plotting.scatter_matrix(df[['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']],\n",
    "                           alpha=0.2, figsize=(12, 12), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e86b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other central tendency measures: Median, Harmonic Mean\n",
    "# Variable temp\n",
    "print('Median of variable temp: {v1}'.format(v1=st.median(dforest['temp'])))\n",
    "print('Harmonic mean of variable temp: {v1}'.format(v1=st.harmonic_mean(dforest['temp'])))\n",
    "print('Variance of variable temp: {v1}'.format(v1=st.variance(dforest['temp'])))\n",
    "print('pVariance (population var) of variable temp: {v1}'.format(v1=st.pvariance(dforest['temp'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the standard deviations (stdev) using the Statistics library\n",
    "print('Forest Fires Dataset\\n')\n",
    "print('Std of variable X: {v1}'.format(v1=st.stdev(dforest['X'])))\n",
    "print('Std of variable Y: {v1}'.format(v1=st.stdev(dforest['Y'])))\n",
    "print('Std of variable FFMC: {v1}'.format(v1=st.stdev(dforest['FFMC'])))\n",
    "print('Std of variable DMC: {v1}'.format(v1=st.stdev(dforest['DMC'])))\n",
    "print('Std of variable DC: {v1}'.format(v1=st.stdev(dforest['DC'])))\n",
    "print('Std of variable ISI: {v1}'.format(v1=st.stdev(dforest['ISI'])))\n",
    "print('Std of variable temp: {v1}'.format(v1=st.stdev(dforest['temp'])))\n",
    "print('Std of variable RH: {v1}'.format(v1=st.stdev(dforest['RH'])))\n",
    "print('Std of variable wind: {v1}'.format(v1=st.stdev(dforest['wind'])))\n",
    "print('Std of variable rain: {v1}'.format(v1=st.stdev(dforest['rain'])))\n",
    "print('Std of variable area: {v1}'.format(v1=st.stdev(dforest['area'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe632280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the data using the Pandas library\n",
    "dforest1 = dforest.iloc[:,2:4]  # Select the nominal variables ['month','day']\n",
    "dforest2 = dforest.drop(['month','day'],axis=1)  # Remove nominal variables ['month','day']\n",
    "\n",
    "# Numeric variables \n",
    "print('Mean of the numeric variables\\n',dforest2.mean())\n",
    "print('\\nStd of the numeric variables\\n',dforest2.std())\n",
    "print('\\nMin of the numeric variables\\n',dforest2.min())\n",
    "print('\\nQuartiles of the numeric variables\\n',dforest2.quantile([.25,.5,.75]))\n",
    "print('\\nMax of the numeric variables\\n',dforest2.max())\n",
    "print('\\nAmplitude of the numeric variables\\n',dforest2.max()-dforest2.min())\n",
    "print('\\nCoefficient of Variation (%) of the numeric variables\\n',(dforest2.std()/dforest2.mean())*100)\n",
    "\n",
    "# Nominal variables\n",
    "print('\\nMode of the nominal variables\\n',dforest1.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d21f2c",
   "metadata": {},
   "source": [
    "## Extra Codes: Central Tendency and Dispersion Measures\n",
    "### All Variables at Once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the data using the describe() method from the Pandas library\n",
    "print('Forest Fires Dataset\\n')\n",
    "print('Numerical variables \\n',dforest.describe().round(2))\n",
    "print('\\nNominal variable: month \\n',dforest['month'].describe())\n",
    "print('\\nNominal variable: day \\n',dforest['day'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Shape Measures using the skew() and kurtosis methods from the Pandas library\n",
    "print('Forest Fires Dataset\\n')\n",
    "print('Numerical variables skew\\n',dforest2.skew())  # dforest2 contains only the numeric variables\n",
    "print('Numerical variables kurtosis\\n',dforest2.kurtosis())  # dforest2 contains only the numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01edd2a",
   "metadata": {},
   "source": [
    "## Extra Codes: Association Measures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f751d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating covariance between variables (pairwise) using Numpy\n",
    "print('Covariance between FFMC and DMC:', np.cov(dforest['FFMC'],dforest['DMC'])[0][1])  # Index[0][1] is the covariance between var1 and var2\n",
    "print('Covariance between DMC and DC:', np.cov(dforest['DMC'],dforest['DC'])[0][1])\n",
    "print('Covariance between Temperature and Relative Humidity:', np.cov(dforest['temp'],dforest['RH'])[0][1])\n",
    "print('Covariance between Rain and Temperature:', np.cov(dforest['rain'],dforest['temp'])[0][1])\n",
    "print('Covariance between Wind and Temperature:', np.cov(dforest['wind'],dforest['temp'])[0][1])\n",
    "print('Covariance between Wind and Rain:', np.cov(dforest['wind'],dforest['rain'])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bf63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Covariance Matrix of the numeric variables using Numpy\n",
    "np.cov(dforest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating correlation between variables (pairwise) using Numpy\n",
    "print('Correlation between FFMC and DMC:', np.corrcoef(dforest['FFMC'],dforest['DMC'])[0][1])  # Index[0][1] is the covariance between var1 and var2\n",
    "print('Correlation between DMC and DC:', np.corrcoef(dforest['DMC'],dforest['DC'])[0][1])\n",
    "print('Correlation between Temperature and Relative Humidity:', np.corrcoef(dforest['temp'],dforest['RH'])[0][1])\n",
    "print('Correlation between Rain and Temperature:', np.corrcoef(dforest['rain'],dforest['temp'])[0][1])\n",
    "print('Correlation between Wind and Temperature:', np.corrcoef(dforest['wind'],dforest['temp'])[0][1])\n",
    "print('Correlation between Wind and Rain:', np.corrcoef(dforest['wind'],dforest['rain'])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix among all numeric variables in the DataFrame using Pandas\n",
    "dforest2.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec1af0",
   "metadata": {},
   "source": [
    "## Extra Codes: Analysis Through Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting all frequency distributions in a single figure to analyze Skewness and Kurtosis using Matplotlib and Seaborn\n",
    "# Variables X, Y, rain and wind were discarded\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.subplot(3,3,1), sns.histplot(dforest.iloc[:,2], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,2), sns.histplot(dforest.iloc[:,3], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,3), sns.histplot(dforest.iloc[:,4], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,4), sns.histplot(dforest.iloc[:,5], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,5), sns.histplot(dforest.iloc[:,6], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,6), sns.histplot(dforest.iloc[:,7], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,7), sns.histplot(dforest.iloc[:,8], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,8), sns.histplot(dforest.iloc[:,9], bins = 'auto', kde = True)\n",
    "plt.subplot(3,3,9), sns.histplot(dforest.iloc[:,10], bins = 'auto', kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63baea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of the main numeric variables using Matplotlib\n",
    "# Variables X, Y, month and day were discarded\n",
    "data = dforest.to_numpy() # Convert the Series into Array\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.subplot(3,3,1), plt.boxplot(dforest.iloc[:,4]), plt.xlabel('FFMC')\n",
    "plt.subplot(3,3,2), plt.boxplot(data[:,5]), plt.xlabel('DMC')\n",
    "plt.subplot(3,3,3), plt.boxplot(data[:,6]), plt.xlabel('DC')\n",
    "plt.subplot(3,3,4), plt.boxplot(data[:,7]), plt.xlabel('ISI')\n",
    "plt.subplot(3,3,5), plt.boxplot(data[:,8]), plt.xlabel('Temperature')\n",
    "plt.subplot(3,3,6), plt.boxplot(data[:,9]), plt.xlabel('RH')\n",
    "plt.subplot(3,3,7), plt.boxplot(data[:,10]), plt.xlabel('Wind')\n",
    "plt.subplot(3,3,8), plt.boxplot(data[:,11]), plt.xlabel('Rain')\n",
    "plt.subplot(3,3,9), plt.boxplot(data[:,12]), plt.xlabel('Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c268ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of the pairs of variables\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(3,2,1)\n",
    "plt.scatter(dforest.iloc[:,4], dforest.iloc[:,5], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('FFMC'), plt.ylabel('DMC')\n",
    "plt.subplot(3,2,2)\n",
    "plt.scatter(dforest.iloc[:,5], dforest.iloc[:,6], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('DMC'), plt.ylabel('DC')\n",
    "plt.subplot(3,2,3)\n",
    "plt.scatter(dforest.iloc[:,8], dforest.iloc[:,9], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('Temperature'), plt.ylabel('RH')\n",
    "plt.subplot(3,2,4)\n",
    "plt.scatter(dforest.iloc[:,11], dforest.iloc[:,8], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('Rain'), plt.ylabel('Temperature')\n",
    "plt.subplot(3,2,5)\n",
    "plt.scatter(dforest.iloc[:,10], dforest.iloc[:,8], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('Wind'), plt.ylabel('Temperature')\n",
    "plt.subplot(3,2,6)\n",
    "plt.scatter(dforest.iloc[:,10], dforest.iloc[:,11], color = 'red', facecolors = 'none', marker = 'o')\n",
    "plt.title('Forest Fire'), plt.xlabel('Wind'), plt.ylabel('Rain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ffaf1",
   "metadata": {},
   "source": [
    "## Final Challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat all the analyzes performed for the Forest dataset using the Mammo dataset\n",
    "# When necessary, replace missing values and transform nominal variables into numeric "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
